{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "_KxskB7LlQgE",
    "outputId": "ea16047a-a1f0-4b2a-d606-09ea5de7f62d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Processing /home/hanna/.cache/pip/wheels/6a/ae/a3/9926619fb71320153272a879bcae86f4b1e813b5da5e482a80/librosa-0.7.2-py2-none-any.whl\n",
      "Collecting six>=1.3\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting joblib>=0.12\n",
      "  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Using cached SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Using cached scikit_learn-0.20.4-cp27-cp27mu-manylinux1_x86_64.whl (5.5 MB)\n",
      "Processing /home/hanna/.cache/pip/wheels/19/90/bb/f45e7cc1cfc8f5299c12511fccefcca90c801de995a4e7eb00/resampy-0.2.2-py2-none-any.whl\n",
      "Collecting numba>=0.43.0\n",
      "  Using cached numba-0.47.0-cp27-cp27mu-manylinux1_x86_64.whl (3.6 MB)\n",
      "Processing /home/hanna/.cache/pip/wheels/d4/9d/5a/af74ada095bef363718acb606e89f006da4e1564cecab24f34/audioread-2.1.8-py2-none-any.whl\n",
      "Collecting decorator>=3.0.0\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting scipy>=1.0.0\n",
      "  Using cached scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)\n",
      "Collecting numpy>=1.15.0\n",
      "  Using cached numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)\n",
      "Collecting cffi>=1.0\n",
      "  Using cached cffi-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl (388 kB)\n",
      "Collecting enum34; python_version < \"3.4\"\n",
      "  Using cached enum34-1.1.10-py2-none-any.whl (11 kB)\n",
      "Collecting llvmlite>=0.31.0dev0\n",
      "  Using cached llvmlite-0.32.1.tar.gz (104 kB)\n",
      "Collecting singledispatch; python_version < \"3.4\"\n",
      "  Using cached singledispatch-3.4.0.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting funcsigs; python_version < \"3.3\"\n",
      "  Using cached funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: setuptools in /home/hanna/deployproject/lib/python2.7/site-packages (from numba>=0.43.0->librosa) (44.1.1)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: llvmlite\n",
      "  Building wheel for llvmlite (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/hanna/deployproject/bin/python2 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-a3Ep4w/llvmlite/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-a3Ep4w/llvmlite/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-dL3er9\n",
      "       cwd: /tmp/pip-install-a3Ep4w/llvmlite/\n",
      "  Complete output (7 lines):\n",
      "  running bdist_wheel\n",
      "  /home/hanna/deployproject/bin/python2 /tmp/pip-install-a3Ep4w/llvmlite/ffi/build.py\n",
      "    File \"/tmp/pip-install-a3Ep4w/llvmlite/ffi/build.py\", line 122\n",
      "      raise ValueError(msg.format(_ver_check_skip)) from e\n",
      "                                                       ^\n",
      "  SyntaxError: invalid syntax\n",
      "  error: command '/home/hanna/deployproject/bin/python2' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for llvmlite\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for llvmlite\n",
      "Failed to build llvmlite\n",
      "Installing collected packages: six, joblib, pycparser, cffi, soundfile, numpy, scipy, scikit-learn, enum34, llvmlite, singledispatch, funcsigs, numba, resampy, audioread, decorator, librosa\n",
      "    Running setup.py install for llvmlite ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/hanna/deployproject/bin/python2 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-a3Ep4w/llvmlite/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-a3Ep4w/llvmlite/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-QhspHA/install-record.txt --single-version-externally-managed --compile --install-headers /home/hanna/deployproject/include/site/python2.7/llvmlite\n",
      "         cwd: /tmp/pip-install-a3Ep4w/llvmlite/\n",
      "    Complete output (10 lines):\n",
      "    running install\n",
      "    running build\n",
      "    got version from file /tmp/pip-install-a3Ep4w/llvmlite/llvmlite/_version.py {'version': '0.32.1', 'full': 'aa11b129c0b55973067422397821ae6d44fa5e70'}\n",
      "    running build_ext\n",
      "    /home/hanna/deployproject/bin/python2 /tmp/pip-install-a3Ep4w/llvmlite/ffi/build.py\n",
      "      File \"/tmp/pip-install-a3Ep4w/llvmlite/ffi/build.py\", line 122\n",
      "        raise ValueError(msg.format(_ver_check_skip)) from e\n",
      "                                                         ^\n",
      "    SyntaxError: invalid syntax\n",
      "    error: command '/home/hanna/deployproject/bin/python2' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /home/hanna/deployproject/bin/python2 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-a3Ep4w/llvmlite/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-a3Ep4w/llvmlite/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-QhspHA/install-record.txt --single-version-externally-managed --compile --install-headers /home/hanna/deployproject/include/site/python2.7/llvmlite Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qU7j6CeqKjLz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcqeVa0GlU6E"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "\n",
    "def extract_spectrum(file_name, file_length=5, bin_factor=4, **kwargs):\n",
    "    \"\"\"\n",
    "    file_length is the target time length of the file in seconds\n",
    "    bin_factor is the amount by which we enlarge the time bins from 512 samples:\n",
    "    Extract mel spectrogram from audio file `file_name`\n",
    "    \"\"\"\n",
    "\n",
    "    X, sample_rate = librosa.core.load(file_name)\n",
    "    file_name = file_name.split('/')[-1]\n",
    "    target_name = file_name[:-4]\n",
    "    target_length = int(file_length * sample_rate)\n",
    "    target = np.zeros(target_length)\n",
    "    if X.shape[0] >= target_length:\n",
    "        target = X[:target_length]\n",
    "    else:\n",
    "        target[:X.shape[0]] = X\n",
    "    X = target\n",
    "    mel = librosa.feature.melspectrogram(X, sr=sample_rate, hop_length=512 * bin_factor).T\n",
    "    print(file_name, ' loaded with shape ', mel.shape)\n",
    "    return mel\n",
    "#     loadname = './data/' + target_name\n",
    "#     if not Path(loadname).is_file():\n",
    "#       np.save(loadname, mel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-EGUmNFT5zjs",
    "outputId": "a1ca381f-a212-4ba0-983c-3b4f93856bd8"
   },
   "outputs": [],
   "source": [
    "# import os \n",
    "\n",
    "# cur_dir = './pygender/test_data/AudioSet/'\n",
    "# genders = ['female', 'male']\n",
    "# data = []\n",
    "\n",
    "# for gen in genders:\n",
    "#     data_dir = cur_dir + (str(gen) + '_clips/')\n",
    "#     for filename in os.listdir(data_dir):\n",
    "#         extract_spectrum(data_dir + filename)\n",
    "#         data.append(('data/'+filename, gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "pAl1kC2I539y",
    "outputId": "580d31f9-2000-4246-904d-93820e3a9b91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/1SCwc3vQsWA.wav</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/35KLb0tUd0U.wav</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/-IAuM2eOMKI.wav</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/-tN-vxr1HjM.wav</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/6FpFqBxK1fE.wav</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  gender\n",
       "0  data/1SCwc3vQsWA.wav  female\n",
       "1  data/35KLb0tUd0U.wav  female\n",
       "2  data/-IAuM2eOMKI.wav  female\n",
       "3  data/-tN-vxr1HjM.wav  female\n",
       "4  data/6FpFqBxK1fE.wav  female"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# df = pd.DataFrame(data, columns = ['filename', 'gender'])\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "sd1F_52X81xX",
    "outputId": "e959a263-71fc-4bd5-8b08-fbd800634ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting SpeechRecognition\n",
      "  Using cached SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ByRteI38zpV"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from tensorflow.keras.models import load_model\n",
    "#from text_to_speech import get_large_audio_transcription\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "ZEPVDZCG9IMs",
    "outputId": "382622fa-01a6-4feb-e732-6054c5100fc9"
   },
   "outputs": [],
   "source": [
    "LABEL2INT = {'female':0,\n",
    "            'male':1}\n",
    "\n",
    "INT2LABEL = {0: 'female',\n",
    "             1: 'male'}\n",
    "\n",
    "shape = (54, 128,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "dny8XuN_mUlE",
    "outputId": "512d136e-f853-4451-b116-4b768d066af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gettysburg10.wav  loaded with shape  (54, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28677973]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model = load_model(\"Daniel/best_model_final.h5\")\n",
    "\n",
    "testfile = extract_spectrum('hanna/gettysburg10.wav').reshape(1,*shape)\n",
    "\n",
    "\n",
    "reconstructed_model.predict(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from flask import Flask, request, jsonify\n",
    "# from tensorflow.keras.models import load_model\n",
    "# import numpy as np\n",
    "# import json\n",
    "\n",
    "# app = Flask(__name__) \n",
    "\n",
    "# def open_model(filename = 'best_model_final.h5'):\n",
    "    \n",
    "#     \"\"\" Given filename, returns the model \n",
    "#     param filename: filepath for model\n",
    "#     return : pretrained model \"\"\"\n",
    "\n",
    "#     return load_model(filename)\n",
    "\n",
    "# def predict_from_model(X):\n",
    "    \n",
    "#     \"\"\" Given X, returns a prediction \n",
    "#     param X: the feature values to consider\n",
    "#     returns pred_pickle: the prediction \"\"\"\n",
    "#     model = open_model()\n",
    "#     if not isinstance(X, np.ndarray):\n",
    "#         X = np.array(eval(str(X)))\n",
    "#     if len(X.shape) == 1:\n",
    "#         X = X[np.newaxis , :]  \n",
    "#     pred_pickle = model.predict(X)\n",
    "#     return str(pred_pickle[0:X.shape[0]])\n",
    "\n",
    "# @app.route('/')\n",
    "# def enter():\n",
    "#     return 'Welcome!'\n",
    "# @app.route('/predict_single')\n",
    "# def predict_single():\n",
    "#     \"\"\" Returns prediction for given parameters\"\"\"\n",
    "#     pred_array = np.zeros(len(cols))\n",
    "    \n",
    "#     for i, col in enumerate(cols):\n",
    "#         pred_array[i] = request.args.get(col)\n",
    "#     try:\n",
    "#         return use_pickle(pred_array)\n",
    "#     except:\n",
    "#         return use_pickle(np.zeros(len(cols)))\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     data = request.get_json()\n",
    "#     prediction = use_pickle(data)\n",
    "\n",
    "#     return jsonify(prediction)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     global model\n",
    "#     model = open_model()\n",
    "#     port = os.environ.get('PORT')\n",
    "#     if port:\n",
    "#         app.run(host='0.0.0.0', port=int(port))\n",
    "#     else:\n",
    "#         app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "i_6HgRAQnr4G",
    "outputId": "8f35e80b-3d3b-4b62-9ffe-427cf7ad409d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.24.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSeGqaQYme8W"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bnD8iACHa8S"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_translation(output, gender):\n",
    "    heb_I =  'אני'\n",
    "    heb_she = 'היא'\n",
    "    heb_he = 'הוא'\n",
    "    ind = []\n",
    "    translate = ''\n",
    "    lenght = 0\n",
    "    translator = Translator()\n",
    "    replacer = 'I'\n",
    "    \n",
    "\n",
    "    for sentence, val in output:\n",
    "        res = translator.translate(sentence, dest='he').text\n",
    "        res_list = re.findall(r\"[\\w]+|['.,!?;]\", res)\n",
    "        if val>0:\n",
    "          if gender == 'female':\n",
    "            replacer = 'she'\n",
    "            heb_replacer = heb_she\n",
    "          elif gender == 'male':\n",
    "            replacer = 'he'\n",
    "            heb_replacer = heb_he\n",
    "          index = [i for i,x in enumerate(res_list) if x==heb_I][0]\n",
    "          ind.append(index+lenght) \n",
    "        lenght += len(res_list) \n",
    "        sentence_list = re.findall(r\"[\\w]+|['.,!?;]\", sentence)\n",
    "        sentence = ' '.join([replacer if word == 'I' else word for word in sentence_list])\n",
    "        translate += \" \" + sentence\n",
    "    gender_res = translator.translate(translate, dest='he').text\n",
    "    gender_res_list = re.findall(r\"[\\w]+|['.,!?;]\", gender_res)\n",
    "    for i in ind:\n",
    "        if gender_res_list[i] ==  heb_replacer:\n",
    "          gender_res_list[i] = heb_I\n",
    "        elif gender_res_list[i-1] ==  heb_replacer:\n",
    "          gender_res_list[i-1] = heb_I\n",
    "        elif gender_res_list[i+1] ==  heb_replacer:\n",
    "          gender_res_list[i+1] = heb_I\n",
    "    print(\"\"\"\\n\\nGender Change : {} : {} => {}\"\"\".format(\n",
    "                                                    gender,\n",
    "                                                    ' '.join([x[0] for x in output]),\n",
    "                                                    ' '.join(gender_res_list))\n",
    "                                                    )\n",
    "    return ' '.join(gender_res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBg8XYDMo5Rz"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "present_tenses = ['VBP', 'VBZ','VBG']\n",
    "\n",
    "\n",
    "def determine_chunks(pronouns, vals, text, \n",
    "                     present_tenses = present_tenses):\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    iterations = len(pronouns)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        start = vals[i]\n",
    "        stop = None \n",
    "        \n",
    "        if i != (iterations - 1):\n",
    "            stop = vals[i+1]\n",
    "\n",
    "        if pronouns[i] != 'I':\n",
    "            chunks.append((str(text[start:stop]),0))\n",
    "            continue\n",
    "            \n",
    "\n",
    "        present_verbs_change = [word for word in text[start:stop]\n",
    "                                if word.tag_ in\n",
    "                                present_tenses]\n",
    "\n",
    "        if len(present_verbs_change) == 0:\n",
    "            chunks.append((str(text[start:stop]),0))\n",
    "            continue\n",
    "\n",
    "        chunks.append((str(text[start:stop]),1))\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ko-hPJkVo3h-"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "\n",
    "def determine_tense_input(sentence, present_tenses = present_tenses): \n",
    "    \n",
    "    \"\"\" Seperates words into chunks based on subjects of the sentence\n",
    "    and sends them to the determine_chunks function to determine\n",
    "    if that chunk requires further manipulation or not \n",
    "    param ....\n",
    "    .....\n",
    "    ....\n",
    "    returns: list of tuples (portion, int) where 1 means the chunk\n",
    "    requires further manipulation and 0 means it can be left as is \"\"\"\n",
    "\n",
    "    text = nlp(sentence)\n",
    "    \n",
    "    present = len([word for word in text \n",
    "                    if word.tag_ in present_tenses])\n",
    "    \n",
    "    if present == 0 :\n",
    "        return [(sentence,0)]\n",
    "    \n",
    "    sub_toks = list(sorted([ (i, tok) for i, tok \n",
    "                            in enumerate(text)\n",
    "                            if tok.dep_ == \"nsubj\" ]))\n",
    "\n",
    "\n",
    "    vals = [x[0] for x in sub_toks]\n",
    "    pronouns = [str(x[1]) for x in sub_toks]\n",
    "    \n",
    "    if 'I' not in pronouns:\n",
    "        return [(sentence,0)]\n",
    "            \n",
    "    return determine_chunks(pronouns, vals, text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S_-xtVy7pJDS",
    "outputId": "1e0c7872-117f-4bb9-80a3-d4a5746ad7db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDJqdJnIpbZU"
   },
   "outputs": [],
   "source": [
    "#!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "7-LxHsmdpMRn",
    "outputId": "d97d314f-3fcd-40dc-f738-8fe1d8b59108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  female\n",
      "True :  male\n",
      "__________________\n",
      "Audio : \n",
      "\n",
      "[(\"For european race driver it seems like an impossible goal to become a nascar champion. Still a while ago we simply doesn't have a nascar championship in europe. \", 0)]\n",
      "\n",
      "\n",
      "Gender Change : male : For european race driver it seems like an impossible goal to become a nascar champion. Still a while ago we simply doesn't have a nascar championship in europe.  => עבור נהג המירוצים האירופי זה נראה כמו מטרה בלתי אפשרית להפוך לאלוף נשק . עדיין לפני זמן מה פשוט אין לנו אליפות נשק באירופה .\n",
      "עבור נהג המירוצים האירופי זה נראה כמו מטרה בלתי אפשרית להפוך לאלוף נשק . עדיין לפני זמן מה פשוט אין לנו אליפות נשק באירופה .\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "### THIS NEEDS TO CHANGE FOR INFERENCE MAIN\n",
    "### CURRENTLY IT'S ASSUMING THERE ARE TEST FOLDERS\n",
    "\n",
    "\n",
    "test_ind = data['indices_test'][0]\n",
    "\n",
    "test_file , test_gender = df.iloc[test_ind]['filename'], df.iloc[test_ind]['gender']\n",
    "\n",
    "gend_folder = 'female_clips/'\n",
    "if test_gender =='male':\n",
    "  gend_folder = 'male_clips/'\n",
    "\n",
    "test_file = 'pygender/test_data/AudioSet/' + gend_folder + test_file.split('/')[-1]\n",
    "\n",
    "sing_shape = data['X_test'][0].shape\n",
    "test_vals = data['X_test'][0].reshape(1,*sing_shape)\n",
    "\n",
    "pred = model.predict(test_vals)\n",
    "pred = pred[0][0]\n",
    "\n",
    "print('Prediction : ', INT2LABEL[round(pred)])\n",
    "print('True : ', test_gender)\n",
    "print('__________________')\n",
    "chunks = get_large_audio_transcription(test_file)\n",
    "\n",
    "print('Audio : \\n') #,chunks)\n",
    "\n",
    "split_sentence = determine_tense_input(chunks)\n",
    "print(split_sentence)\n",
    "print(get_translation(split_sentence, test_gender))\n",
    "#print('\\nAudio : \\n\\n',get_large_audio_transcription(te))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "FullPipe1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
