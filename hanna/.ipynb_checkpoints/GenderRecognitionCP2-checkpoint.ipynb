{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gender Voice Recognition \n",
    "\n",
    "Please see the [README](https://github.com/hannahier94/ITC_FinalProject_Gender_Voice_Recognition/blob/master/README.md) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.200355Z",
     "start_time": "2020-08-27T09:39:28.562402Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM #, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.280354Z",
     "start_time": "2020-08-27T09:39:31.204360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/cv-other-train/sample-069205.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/cv-other-train/sample-080873.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/cv-other-train/sample-105595.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  gender\n",
       "0  data/cv-other-train/sample-069205.npy  female\n",
       "1  data/cv-valid-train/sample-063134.npy  female\n",
       "2  data/cv-other-train/sample-080873.npy  female\n",
       "3  data/cv-other-train/sample-105595.npy  female\n",
       "4  data/cv-valid-train/sample-144613.npy  female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"balanced-all.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have exactly a 50/50 split of audio files per gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    33469\n",
       "male      33469\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.296355Z",
     "start_time": "2020-08-27T09:39:31.282354Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path=\"balanced-all.csv\",vector_length=128):\n",
    "    \n",
    "    \"\"\"A function to load gender recognition dataset from \n",
    "    `data` folder. After the second run, this will load from \n",
    "    results/features.npy  and results/labels.npy files\n",
    "    as it is much faster!\n",
    "    param path: path where you data is located\n",
    "    param vector_length : size of each sample \"\"\"\n",
    "    \n",
    "    # make sure results folder exists\n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "    \n",
    "    # if features & labels already loaded individually and bundled, \n",
    "    # load them from there instead\n",
    "    if os.path.isfile(\"results/features.npy\") and os.path.isfile(\"results/labels.npy\"):\n",
    "        X = np.load(\"results/features.npy\")\n",
    "        y = np.load(\"results/labels.npy\")\n",
    "        return X, y\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    n_samples = len(df)\n",
    "    \n",
    "    # get total male samples\n",
    "    n_male_samples = len(df[df['gender'] == 'male'])\n",
    "    # get total female samples\n",
    "    n_female_samples = len(df[df['gender'] == 'female'])\n",
    "    print(\"Total samples:\", n_samples)\n",
    "    print(\"Total male samples:\", n_male_samples)\n",
    "    print(\"Total female samples:\", n_female_samples)\n",
    "    \n",
    "    # initialize an empty array for all audio features\n",
    "    X = np.zeros((n_samples, vector_length))\n",
    "    # initialize an empty array for all audio labels (1 for male and 0 for female)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    \n",
    "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df['filename'], df['gender'])), \n",
    "                                            \"Loading data\", total=n_samples):\n",
    "        features = np.load(filename)\n",
    "        X[i] = features\n",
    "        y[i] = label2int[gender]\n",
    "    \n",
    "    # save the audio features and labels into files\n",
    "    # so we won't load each one of them next run\n",
    "    np.save(\"results/features\", X)\n",
    "    np.save(\"results/labels\", y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.312381Z",
     "start_time": "2020-08-27T09:39:31.298357Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
    "    \n",
    "    \"\"\" A function to split X,y data\n",
    "    param X: X data\n",
    "    param y: y data\n",
    "    param test_size: test fraction \n",
    "    param:valid_size: validation fraction \n",
    "    return: a dictionary of X/y for train/val/test \"\"\"\n",
    "    \n",
    "    # split training set and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
    "    # split training set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
    "    # return a dictionary of values\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"y_test\": y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.408354Z",
     "start_time": "2020-08-27T09:39:31.314372Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = load_data()\n",
    "\n",
    "# split the data into training, validation and testing sets\n",
    "data = split_data(X, y, test_size=0.1, valid_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Set Up\n",
    "\n",
    "For the model set up, we added in various dropouts (0.1 & 0.3) and regularizations (l2 applied on different combinations of layers) , but overall the regularization did not have significant effects on the model. We acheived the best results when using the following architecure : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.423357Z",
     "start_time": "2020-08-27T09:39:31.410356Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vector_length=128):\n",
    "    \n",
    "    \"\"\"5 hidden dense layers from 256 units to 64.\n",
    "    param vector_length : size of each sample \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    #model.add(Dropout(0.01))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    #model.add(Dropout(0.01))\n",
    "    \n",
    "    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # using binary crossentropy as it's male/female classification (binary)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    \n",
    "    # print summary of the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:31.945991Z",
     "start_time": "2020-08-27T09:39:31.427359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hanna/anaconda3/envs/finalproject/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/hanna/anaconda3/envs/finalproject/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "We used Early stopping with the modes \"val_loss\", \"val_accuracy\", and \"min\". We acheived the best accuracy when using the \"min\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:59.527328Z",
     "start_time": "2020-08-27T09:39:31.948959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54219 samples, validate on 6025 samples\n",
      "Epoch 1/300\n",
      "54219/54219 [==============================] - 2s 42us/sample - loss: 0.4294 - acc: 0.8295 - val_loss: 0.3630 - val_acc: 0.8508\n",
      "Epoch 2/300\n",
      "54219/54219 [==============================] - 2s 37us/sample - loss: 0.3263 - acc: 0.8711 - val_loss: 0.3366 - val_acc: 0.8614\n",
      "Epoch 3/300\n",
      "54219/54219 [==============================] - 2s 32us/sample - loss: 0.2849 - acc: 0.8881 - val_loss: 0.2646 - val_acc: 0.8989\n",
      "Epoch 4/300\n",
      "54219/54219 [==============================] - 2s 37us/sample - loss: 0.2742 - acc: 0.8929 - val_loss: 0.2701 - val_acc: 0.8943\n",
      "Epoch 5/300\n",
      "54219/54219 [==============================] - 2s 39us/sample - loss: 0.2469 - acc: 0.9040 - val_loss: 0.2391 - val_acc: 0.9090\n",
      "Epoch 6/300\n",
      "54219/54219 [==============================] - 2s 37us/sample - loss: 0.2399 - acc: 0.9081 - val_loss: 0.2456 - val_acc: 0.9097\n",
      "Epoch 7/300\n",
      "54219/54219 [==============================] - 2s 40us/sample - loss: 0.2260 - acc: 0.9124 - val_loss: 0.2346 - val_acc: 0.9100\n",
      "Epoch 8/300\n",
      "54219/54219 [==============================] - 2s 39us/sample - loss: 0.2198 - acc: 0.9163 - val_loss: 0.2353 - val_acc: 0.9097\n",
      "Epoch 9/300\n",
      "54219/54219 [==============================] - 2s 34us/sample - loss: 0.2073 - acc: 0.9188 - val_loss: 0.2343 - val_acc: 0.9122\n",
      "Epoch 10/300\n",
      "54219/54219 [==============================] - 2s 41us/sample - loss: 0.2021 - acc: 0.9208 - val_loss: 0.2448 - val_acc: 0.9107\n",
      "Epoch 11/300\n",
      "54219/54219 [==============================] - 2s 41us/sample - loss: 0.1965 - acc: 0.9243 - val_loss: 0.2418 - val_acc: 0.9122\n",
      "Epoch 12/300\n",
      "54219/54219 [==============================] - 2s 40us/sample - loss: 0.1899 - acc: 0.9273 - val_loss: 0.2349 - val_acc: 0.9150\n",
      "Epoch 13/300\n",
      "54219/54219 [==============================] - 2s 40us/sample - loss: 0.1811 - acc: 0.9299 - val_loss: 0.2384 - val_acc: 0.9120\n",
      "Epoch 14/300\n",
      "54219/54219 [==============================] - 2s 41us/sample - loss: 0.1808 - acc: 0.9305 - val_loss: 0.2162 - val_acc: 0.9197\n",
      "Epoch 15/300\n",
      "54219/54219 [==============================] - 2s 41us/sample - loss: 0.1743 - acc: 0.9334 - val_loss: 0.2269 - val_acc: 0.9183\n",
      "Epoch 16/300\n",
      "54219/54219 [==============================] - 2s 41us/sample - loss: 0.1744 - acc: 0.9333 - val_loss: 0.2202 - val_acc: 0.9233\n",
      "Epoch 17/300\n",
      "54219/54219 [==============================] - 2s 40us/sample - loss: 0.1659 - acc: 0.9365 - val_loss: 0.2182 - val_acc: 0.9202\n",
      "Epoch 18/300\n",
      "54219/54219 [==============================] - 2s 40us/sample - loss: 0.1594 - acc: 0.9386 - val_loss: 0.2205 - val_acc: 0.9213\n",
      "Epoch 19/300\n",
      "54219/54219 [==============================] - 2s 42us/sample - loss: 0.1518 - acc: 0.9416 - val_loss: 0.2278 - val_acc: 0.9243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fccae021940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "tensorboard = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# define early stopping to stop training after 5 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", \n",
    "                               patience=5, \n",
    "                               restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 300\n",
    "\n",
    "# train the model using the training set and validating using validation set\n",
    "model.fit(data[\"X_train\"], \n",
    "          data[\"y_train\"], \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size, \n",
    "          validation_data=(data[\"X_valid\"], \n",
    "                           data[\"y_valid\"]),\n",
    "          callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T09:39:59.765317Z",
     "start_time": "2020-08-27T09:39:59.529315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model using 6694 samples...\n",
      "Loss: 0.2281\n",
      "Accuracy: 92.10%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model using the testing set\n",
    "print(f\"\"\"Evaluating the model using \n",
    "        {len(data['X_test'])} samples...\"\"\")\n",
    "\n",
    "loss, accuracy = model.evaluate(data[\"X_test\"],\n",
    "                                data[\"y_test\"], \n",
    "                                verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
