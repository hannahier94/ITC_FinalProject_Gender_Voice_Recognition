{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "GenderRecognitionCP2-HannaCopy1 (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbwmSb8GKivl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Gender Voice Recognition \n",
        "\n",
        "Please see the [README](https://github.com/hannahier94/ITC_FinalProject_Gender_Voice_Recognition/blob/master/README.md) for more information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G58WU676Kivn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2h6PCfWL_pN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "66e15e6f-c3d2-46d2-e6c6-2a5d4d05412d"
      },
      "source": [
        "! pip install googletrans"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/82/4bd4b7d9c0d1dc0fbfbc2a1e00138e7f3ab85bc239358fe9b78aa2ab586d/sniffio-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/07/12dd706501a3212a9774feb69d6a2333963a2da19ba98861ab23f2439f3d/hstspreload-2020.9.9-py3-none-any.whl (953kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Collecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n",
            "\u001b[?25hCollecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-cp36-none-any.whl size=15736 sha256=70c98ced70eee2b7c3647e1f82045543d49d0e4c5f6514ac68674a7700071d4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=a6aa75604376c5746f027484182897c5764789eed0dfa2fd5f4e304fb8870a76\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: h11, hyperframe, hpack, h2, immutables, contextvars, sniffio, httpcore, hstspreload, rfc3986, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.9.9 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.200355Z",
          "start_time": "2020-08-27T09:39:28.562402Z"
        },
        "id": "kyqRBv__Kivs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "from googletrans import Translator\n",
        "import speech_recognition as sr\n",
        "from text_to_speech import get_large_audio_transcription\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.280354Z",
          "start_time": "2020-08-27T09:39:31.204360Z"
        },
        "id": "p-a6b3D7Kivw",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce2dd268-d7a7-45c4-920c-fae5b0d3ab20"
      },
      "source": [
        "rawdata_path = 'gender-recognition-by-voice/'\n",
        "cat_file = 'balanced-all.csv'\n",
        "\n",
        "df = pd.read_csv(rawdata_path + cat_file)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/cv-other-train/sample-069205.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/cv-other-train/sample-080873.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/cv-other-train/sample-105595.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                filename  gender\n",
              "0  data/cv-other-train/sample-069205.npy  female\n",
              "1  data/cv-valid-train/sample-063134.npy  female\n",
              "2  data/cv-other-train/sample-080873.npy  female\n",
              "3  data/cv-other-train/sample-105595.npy  female\n",
              "4  data/cv-valid-train/sample-144613.npy  female"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI8wq288Kiv1",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we have exactly a 50/50 split of audio files per gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m878VDjIKiv3",
        "colab_type": "code",
        "colab": {},
        "outputId": "8ce5ed31-ac93-4390-c1fd-0f3381509c1f"
      },
      "source": [
        "df['gender'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "female    33469\n",
              "male      33469\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.296355Z",
          "start_time": "2020-08-27T09:39:31.282354Z"
        },
        "id": "mEHHcuMqKiv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL2INT = {'female':0,\n",
        "            'male':1}\n",
        "\n",
        "INT2LABEL = {0: 'female',\n",
        "             1: 'male'}\n",
        "\n",
        "result_path = 'results'\n",
        "feature_path = '/features.npy'\n",
        "label_path = '/labels.npy'\n",
        "\n",
        "\n",
        "def load_data(path=rawdata_path, \n",
        "              df = df, \n",
        "              result_path = result_path,\n",
        "              vector_length=128,\n",
        "              feature_path = feature_path,\n",
        "              label_path = label_path,\n",
        "              file_col = 'filename',\n",
        "              gender_col = 'gender'):\n",
        "    \n",
        "    \"\"\"A function to load gender recognition dataset from \n",
        "    `data` folder. After the second run, this will load from \n",
        "    results/features.npy  and results/labels.npy files\n",
        "    as it is much faster!\n",
        "    param path: path where you data is located\n",
        "    param df: dataframe to use\n",
        "    param result_path : path to store results\n",
        "    param vector_length : size of each sample \n",
        "    param feature_path : path to load/store features\n",
        "    param label_path : path to load/store labels\n",
        "    param file_col: df column to reference files\n",
        "    param gender_col : df column to reference gender labels\n",
        "    returns : X, y data \"\"\"\n",
        "    \n",
        "    feature_path = result_path + feature_path\n",
        "    label_path = result_path + label_path\n",
        "    \n",
        "    if not os.path.isdir(result_path):\n",
        "        os.mkdir(result_path)\n",
        "    \n",
        "    # if features & labels already loaded/bundled, load them \n",
        "    if os.path.isfile(feature_path) and os.path.isfile(label_path):\n",
        "        X = np.load(feature_path)\n",
        "        y = np.load(label_path)\n",
        "        return X, y\n",
        "\n",
        "    n_samples = len(df)\n",
        "    print(\"Total samples:\", n_samples)\n",
        "    \n",
        "    dist = df.gender.value_counts()\n",
        "    \n",
        "    for gender, count in list(zip(dist.index, dist.values)):\n",
        "        print(\"Total {} samples: {}\".format(gender,count))\n",
        "\n",
        "    X = np.zeros((n_samples, vector_length))\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    \n",
        "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df[file_col], \n",
        "                                                         df[gender_col])), \n",
        "                                            \"Loading data\", \n",
        "                                           total = n_samples):\n",
        "        features = np.load(path + filename)\n",
        "        X[i] = features\n",
        "        y[i] = LABEL2INT[gender]\n",
        "    \n",
        "    np.save(feature_path, X)\n",
        "    np.save(label_path, y)\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.312381Z",
          "start_time": "2020-08-27T09:39:31.298357Z"
        },
        "id": "1XYuk06LKiwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(X, y, indicies, test_size=0.1, valid_size=0.1):\n",
        "    \n",
        "    \"\"\" A function to split X,y data\n",
        "    param X: X data\n",
        "    param y: y data\n",
        "    param test_size: test fraction \n",
        "    param:valid_size: validation fraction \n",
        "    return: a dictionary of X/y for train/val/test \"\"\"\n",
        "\n",
        "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, \n",
        "                                                                            indicies,\n",
        "                                                                            test_size=test_size, \n",
        "                                                                            random_state=7)\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
        "                                                          test_size=valid_size, \n",
        "                                                          random_state=7)\n",
        "    return {\n",
        "        \"X_train\": X_train,\n",
        "        \"X_valid\": X_valid,\n",
        "        \"X_test\": X_test,\n",
        "        \"y_train\": y_train,\n",
        "        \"y_valid\": y_valid,\n",
        "        \"y_test\": y_test,\n",
        "        \"indices_train\" : indices_train, \n",
        "        \"indices_test\" : indices_test\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.408354Z",
          "start_time": "2020-08-27T09:39:31.314372Z"
        },
        "scrolled": true,
        "id": "fUncsZvxKiwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = load_data()\n",
        "\n",
        "data = split_data(X, y, \n",
        "                  df.index.to_numpy(), \n",
        "                  test_size=0.1, \n",
        "                  valid_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUnlaRVrKiwL",
        "colab_type": "text"
      },
      "source": [
        "### Model Set Up\n",
        "\n",
        "For the model set up, we added in various dropouts (0.1 & 0.3) and regularizations (l2 applied on different combinations of layers) , but overall the regularization did not have significant effects on the model. We acheived the best results when using the following architecure : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.423357Z",
          "start_time": "2020-08-27T09:39:31.410356Z"
        },
        "id": "ax-7ufpcKiwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We only need one hidden layer \n",
        "## fundamental frequency - to determine male/female represents how high / low the voice sounds\n",
        "## auto correaltion of the signal - first peak = fundamental frequency\n",
        "\n",
        "## mfcc_f0\n",
        "\n",
        "## another possibility : original CNN design\n",
        "\n",
        "## data augmentation to add some noise\n",
        "\n",
        "\n",
        "def create_model(vector_length = 128, \n",
        "                 lr = 0.001, \n",
        "                 loss = \"binary_crossentropy\",\n",
        "                 metric = ['accuracy']) :\n",
        "    \n",
        "    \"\"\"\n",
        "    5 hidden dense layers from 256 units to 64.\n",
        "    param vector_length : size of each sample \n",
        "    param lr: learning rate\n",
        "    param loss: loss eval\n",
        "    param metric: metric to train\n",
        "    returns: model\n",
        "    \"\"\"\n",
        "    \n",
        "    RELU = \"relu\"\n",
        "    SIGMOID = \"sigmoid\"\n",
        "    n_labels = 1\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(256, input_shape=(vector_length,)))\n",
        "    \n",
        "    model.add(Dense(256, activation = RELU ))\n",
        "    model.add(Dense(128, activation = RELU))\n",
        "    model.add(Dense(128, activation = RELU))\n",
        "    model.add(Dense(64, activation = RELU))\n",
        "    \n",
        "    model.add(Dense(n_labels, activation= SIGMOID))\n",
        "    \n",
        "    \n",
        "    optimizer = Adam(learning_rate = lr)\n",
        "    \n",
        "    model.compile(loss = loss, \n",
        "                  metrics = metric, \n",
        "                  optimizer = optimizer)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:31.945991Z",
          "start_time": "2020-08-27T09:39:31.427359Z"
        },
        "id": "KQyMmmQZKiwR",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9ad3842-a25f-4e34-809d-db70f2aa1db4"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 156,545\n",
            "Trainable params: 156,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-1utpKcKiwU",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the Model\n",
        "\n",
        "We used Early stopping with the modes \"val_loss\", \"val_accuracy\", and \"min\". We acheived the best accuracy when using the \"min\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:59.527328Z",
          "start_time": "2020-08-27T09:39:31.948959Z"
        },
        "id": "S3PubT3RKiwV",
        "colab_type": "code",
        "colab": {},
        "outputId": "d56fed27-3911-4b9d-cf2d-152c9ed2b1c6"
      },
      "source": [
        "# use tensorboard to view metrics\n",
        "tensorboard = TensorBoard(log_dir=\"logs\")\n",
        "\n",
        "early_stopping = EarlyStopping(mode = \"min\", \n",
        "                               patience = 5, \n",
        "                               restore_best_weights = True)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 300\n",
        "\n",
        "history = model.fit(data[\"X_train\"], \n",
        "                  data[\"y_train\"], \n",
        "                  epochs=epochs, \n",
        "                  batch_size=batch_size, \n",
        "                  validation_data=(data[\"X_valid\"], \n",
        "                                   data[\"y_valid\"]),\n",
        "                  callbacks=[tensorboard, early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  1/848 [..............................] - ETA: 0s - loss: 0.2266 - accuracy: 0.8906WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0219s). Check your callbacks.\n",
            "848/848 [==============================] - 3s 3ms/step - loss: 0.1575 - accuracy: 0.9381 - val_loss: 0.2234 - val_accuracy: 0.9235\n",
            "Epoch 2/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1518 - accuracy: 0.9415 - val_loss: 0.2360 - val_accuracy: 0.9187\n",
            "Epoch 3/300\n",
            "848/848 [==============================] - 3s 3ms/step - loss: 0.1513 - accuracy: 0.9421 - val_loss: 0.2602 - val_accuracy: 0.9207\n",
            "Epoch 4/300\n",
            "848/848 [==============================] - 3s 3ms/step - loss: 0.1445 - accuracy: 0.9450 - val_loss: 0.2405 - val_accuracy: 0.9213\n",
            "Epoch 5/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1354 - accuracy: 0.9467 - val_loss: 0.2276 - val_accuracy: 0.9235\n",
            "Epoch 6/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1317 - accuracy: 0.9487 - val_loss: 0.2335 - val_accuracy: 0.9154\n",
            "Epoch 7/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1240 - accuracy: 0.9530 - val_loss: 0.2432 - val_accuracy: 0.9223\n",
            "Epoch 8/300\n",
            "848/848 [==============================] - 3s 3ms/step - loss: 0.1288 - accuracy: 0.9506 - val_loss: 0.2349 - val_accuracy: 0.9261\n",
            "Epoch 9/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1156 - accuracy: 0.9563 - val_loss: 0.2311 - val_accuracy: 0.9283\n",
            "Epoch 10/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1126 - accuracy: 0.9571 - val_loss: 0.2509 - val_accuracy: 0.9241\n",
            "Epoch 11/300\n",
            "848/848 [==============================] - 2s 3ms/step - loss: 0.1077 - accuracy: 0.9591 - val_loss: 0.3054 - val_accuracy: 0.9109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-27T09:39:59.765317Z",
          "start_time": "2020-08-27T09:39:59.529315Z"
        },
        "id": "jOG6l8iXKiwZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "e19eb99e-a18a-4b39-e35f-dbffd910fca8"
      },
      "source": [
        "print(\"\\nEvaluating on {} samples...\".format(len(data['X_test'])))\n",
        "print(\"_____________________________\\n\")\n",
        "\n",
        "loss, accuracy = model.evaluate(data[\"X_test\"],\n",
        "                                data[\"y_test\"], \n",
        "                                verbose=0)\n",
        "\n",
        "print(\"Loss: {}\".format(round(loss,5)))\n",
        "print(\"Accuracy: {}% \".format(round(accuracy * 100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on 6694 samples...\n",
            "_____________________________\n",
            "\n",
            "Loss: 0.23114\n",
            "Accuracy: 92.37% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ZKjmkAKiwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_test_path = '/home/hanna/Downloads/final_project/gender-recognition-by-voice/data/cv-other-train/sample-006859.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKRK8B0rKiwh",
        "colab_type": "code",
        "colab": {},
        "outputId": "21c46d27-c149-417b-e718-01b761b7d7a0"
      },
      "source": [
        "\n",
        "test_ind = data['indices_test'][0]\n",
        "\n",
        "test_file , test_gender = df.iloc[test_ind]['filename'], df.iloc[test_ind]['gender']\n",
        "\n",
        "test_vals = data['X_test'][0].reshape(1,-1)\n",
        "\n",
        "pred = model.predict(test_vals)\n",
        "pred = pred[0][0]\n",
        "\n",
        "print('Prediction : ', INT2LABEL[round(pred)])\n",
        "print('True : ', test_gender)\n",
        "print('__________________')\n",
        "#print('Audio : \\n',get_large_audio_transcription(test_file))\n",
        "print('\\nAudio : \\n\\n',get_large_audio_transcription('gettysburg10.wav'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction :  male\n",
            "True :  male\n",
            "__________________\n",
            "\n",
            "Audio : \n",
            "\n",
            " Four score and seven years ago our fathers brought forth on this continent a new nation. Conceived in liberty and dedicated to the proposition that all men are created equal. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8dmBY5NKiwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6110d7e9-0d17-4995-b9f8-c04a8d03ea03"
      },
      "source": [
        "# MFCC f0 (fundamental frequency) detection \n",
        "# cnn \n",
        "# data augmentation \n",
        "# spacy dependency parsing \n",
        "# anaphora resolution \n",
        "# opus project \n",
        "# tatoeba english-hebrew \n",
        "# http://www.manythings.org/anki/ \n",
        "# opus — opensubtitles \n",
        "\n",
        "# anaphora resolution python\n",
        "\n",
        "#https://hebrew-nlp.co.il/ \n",
        "\n",
        "\n",
        "heb_I =  'אני'\n",
        "heb_she = 'היא'\n",
        "heb_he = 'הוא'\n",
        "\n",
        "test_corpus = ['I am testing this.',\n",
        "              'I am walking.',\n",
        "              'I appreciate that she helped because I am confused.']\n",
        "\n",
        "test_gender = ['F', 'M', 'F']\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "for sentence, gender in list(zip(test_corpus, test_gender)):\n",
        "    original = sentence\n",
        "    res = translator.translate(sentence, dest='he').text\n",
        "    \n",
        "    \n",
        "    ind = [i for i,x in enumerate(res.split()) if x == heb_I]\n",
        "    \n",
        "    if gender == 'F':\n",
        "        replacer = 'she '\n",
        "        heb_pron = heb_she\n",
        "    else:\n",
        "        replacer = 'he '\n",
        "        heb_pron = heb_he\n",
        "    sentence = sentence.replace('I ', replacer)\n",
        "    \n",
        "    gender_res = translator.translate(sentence, dest='he').text\n",
        "    \n",
        "    temp = gender_res.split()\n",
        "    for i in ind:\n",
        "        temp[i] = heb_I\n",
        "\n",
        "    print(\"\"\"\\n\\nGender Change : {} : {} => {}\"\"\".format(\n",
        "                                                gender,\n",
        "                                                original,\n",
        "                                                ' '.join(temp)\n",
        "                                                ))\n",
        "\n",
        "    print('______________________________________________________')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Gender Change : F : I am testing this. => אני בודקת את זה.\n",
            "______________________________________________________\n",
            "\n",
            "\n",
            "Gender Change : M : I am walking. => אני הולך.\n",
            "______________________________________________________\n",
            "\n",
            "\n",
            "Gender Change : F : I appreciate that she helped because I am confused. => אני מעריכה שהיא עזרה בגלל אני מבולבלת.\n",
            "______________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-88-R25fKiwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "present_tenses = ['VBP', 'VBZ','VBG']\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WQ3uwupKiwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def determine_chunks(pronouns, vals, text, \n",
        "                     present_tenses = present_tenses):\n",
        "    \n",
        "    chunks = []\n",
        "    \n",
        "    iterations = len(pronouns)\n",
        "    \n",
        "    for i in range(iterations):\n",
        "        \n",
        "        start = vals[i]\n",
        "        stop = None \n",
        "        \n",
        "        if i != (iterations - 1):\n",
        "            stop = vals[i+1]\n",
        "\n",
        "        if pronouns[i] != 'I':\n",
        "            chunks.append((str(text[start:stop]),0))\n",
        "            continue\n",
        "            \n",
        "\n",
        "        present_verbs_change = [word for word in text[start:stop]\n",
        "                                if word.tag_ in\n",
        "                                present_tenses]\n",
        "\n",
        "        if len(present_verbs_change) == 0:\n",
        "            chunks.append((str(text[start:stop]),0))\n",
        "            continue\n",
        "\n",
        "        chunks.append((str(text[start:stop]),1))\n",
        "        \n",
        "    return chunks"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GldhtbBMKiw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "bb2c7997-a600-4dcd-ce72-d6542224933d"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "\n",
        "def determine_tense_input(sentence, present_tenses = present_tenses): \n",
        "    \n",
        "    \"\"\" Seperates words into chunks based on subjects of the sentence\n",
        "    and sends them to the determine_chunks function to determine\n",
        "    if that chunk requires further manipulation or not \n",
        "    param ....\n",
        "    .....\n",
        "    ....\n",
        "    returns: list of tuples (portion, int) where 1 means the chunk\n",
        "    requires further manipulation and 0 means it can be left as is \"\"\"\n",
        "\n",
        "    text = nlp(sentence)\n",
        "    \n",
        "    present = len([word for word in text \n",
        "                    if word.tag_ in present_tenses])\n",
        "    \n",
        "    if present == 0 :\n",
        "        return sentence\n",
        "    \n",
        "    sub_toks = list(sorted([ (i, tok) for i, tok \n",
        "                            in enumerate(text)\n",
        "                            if tok.dep_ == \"nsubj\" ]))\n",
        "\n",
        "\n",
        "    vals = [x[0] for x in sub_toks]\n",
        "    pronouns = [str(x[1]) for x in sub_toks]\n",
        "    \n",
        "    if 'I' not in pronouns:\n",
        "        return sentence\n",
        "            \n",
        "    return determine_chunks(pronouns, vals, text)\n",
        "            \n",
        "    \n",
        "determine_tense_input(\"He was angry, so I left. I am walking away because he told me he is happy. I'm glad this happened\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He was angry, so', 0),\n",
              " ('I left.', 0),\n",
              " ('I am walking away because', 1),\n",
              " ('he told me', 0),\n",
              " ('he is happy.', 0),\n",
              " (\"I'm glad\", 1),\n",
              " ('this happened', 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z3aPcq7Kiw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def get_translation(output, gender):\n",
        "    heb_I =  'אני'\n",
        "    heb_she = 'היא'\n",
        "    heb_he = 'הוא'\n",
        "    ind = []\n",
        "    translate = ''\n",
        "    lenght = 0\n",
        "    translator = Translator()\n",
        "    replacer = 'I'\n",
        "    for sentence, val in output:\n",
        "        res = translator.translate(sentence, dest='he').text\n",
        "        res_list = re.findall(r\"[\\w]+|['.,!?;]\", res)\n",
        "        if val>0:\n",
        "          if gender == 'F':\n",
        "            replacer = 'she'\n",
        "            heb_replacer = heb_she\n",
        "          elif gender == 'M':\n",
        "            replacer = 'he'\n",
        "            heb_replacer = heb_he\n",
        "          index = [i for i,x in enumerate(res_list) if x==heb_I][0]\n",
        "          ind.append(index+lenght) \n",
        "        lenght += len(res_list) \n",
        "        sentence_list = re.findall(r\"[\\w]+|['.,!?;]\", sentence)\n",
        "        sentence = ' '.join([replacer if word == 'I' else word for word in sentence_list])\n",
        "        translate += \" \" + sentence\n",
        "    gender_res = translator.translate(translate, dest='he').text\n",
        "    gender_res_list = re.findall(r\"[\\w]+|['.,!?;]\", gender_res)\n",
        "    for i in ind:\n",
        "        if gender_res_list[i] ==  heb_replacer:\n",
        "          gender_res_list[i] = heb_I\n",
        "        elif gender_res_list[i-1] ==  heb_replacer:\n",
        "          gender_res_list[i-1] = heb_I\n",
        "        elif gender_res_list[i+1] ==  heb_replacer:\n",
        "          gender_res_list[i+1] = heb_I\n",
        "    print(\"\"\"\\n\\nGender Change : {} : {} => {}\"\"\".format(\n",
        "                                                    gender,\n",
        "                                                    ' '.join([x[0] for x in output]),\n",
        "                                                    ' '.join(gender_res_list))\n",
        "                                                    )\n",
        "    return ' '.join(gender_res_list)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdmuJU38LSt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "812adfc1-c0b4-49e9-d506-146dbacf6c09"
      },
      "source": [
        "sentence = \"He was angry, so I left. I am walking away because he told me he is happy. I'm glad this happened\"\n",
        "gender = 'F'\n",
        "split_sentence = determine_tense_input(sentence)\n",
        "print(get_translation(split_sentence, gender))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Gender Change : F : He was angry, so I left. I am walking away because he told me he is happy. I'm glad this happened => הוא כעס , אז עזבתי . אני הולכת כי הוא אמר לי שהוא מאושר . אני שמחה שזה קרה\n",
            "הוא כעס , אז עזבתי . אני הולכת כי הוא אמר לי שהוא מאושר . אני שמחה שזה קרה\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGgE2SipKiw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f08ff580-e79f-400b-c271-9d25179189cc"
      },
      "source": [
        "chunks = \"I, like my other fellows, am happy to be here\"\n",
        "\n",
        "split_sentence = determine_tense_input(chunks)\n",
        "print(get_translation(split_sentence, gender))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Gender Change : F : I, like my other fellows, am happy to be here => אני , כמו חברי האחרים , שמחה להיות כאן\n",
            "אני , כמו חברי האחרים , שמחה להיות כאן\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOsnFDplKixA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_past_tense = \"\"\"  \n",
        "1. I watched TV last week.\n",
        "\n",
        "2. We ate meat with my best friend yesterday.\n",
        "\n",
        "3. The bus stopped a few minutes ago.\n",
        "\n",
        "4. I met my wife 9 years ago.\n",
        "\n",
        "5. She left the school in 2010.\n",
        "\n",
        "6. He bought a new house last month.\n",
        "\n",
        "7. Did she clean her home?\n",
        "\n",
        "8. I read an interesting book last month.\n",
        "\n",
        "9. We did a lot of shopping at the shopping mall.\n",
        "\n",
        "10. He cut his finger and went to hospital.\n",
        "\n",
        "11. She finished her work at six o’clock.\n",
        "\n",
        "12. The rain stopped an hour ago.\n",
        "\n",
        "13. It discovered a new land.\n",
        "\n",
        "14. We watched a movie last weekend.\n",
        "\n",
        "15. We were good friends.\n",
        "\n",
        "16. You were at station.\n",
        "\n",
        "17. I went to bed early yesterday.\n",
        "\n",
        "18. George came home very late last night.\n",
        "\n",
        "19. I forgot my wallet.\n",
        "\n",
        "20. He had a dog last year.\n",
        "\n",
        "21. Last year I traveled to Germany.\n",
        "\n",
        "22. Two boys played with a ball.\n",
        "\n",
        "23. An old lady walked with her cat.\n",
        "\n",
        "24. A nurse brought a little girl baby to the park.\n",
        "\n",
        "25. An old man sat down and read his book.\n",
        "\n",
        "26. A large trunk came around the corner.\n",
        "\n",
        "27. She finished all the exercices.\n",
        "\n",
        "28. I enrolled to the pilates course.\n",
        "\n",
        "29. Dr Smith healed the patient.\n",
        "\n",
        "30. They bought 2 tickets for the U2 concert.\n",
        "\n",
        "31. Michael studied hard all year.\n",
        "\n",
        "32. Did you play football last day?\n",
        "\n",
        "33. I missed the class last week.\n",
        "\n",
        "34. My brother drank a glass of milk 2 hours ago.\n",
        "\n",
        "35. They had a meeting with her colleagues.\n",
        "\n",
        "36. They were students last year.\n",
        "\n",
        "37. He smoked a cigarrette.\n",
        "\n",
        "38. They lived in the Spain.\n",
        "\n",
        "39. Alex changed his place.\n",
        "\n",
        "40. I liked the film.\n",
        "\n",
        "41. Did they lose the match?\n",
        "\n",
        "42. A gardener swept up dead leaves.\n",
        "\n",
        "43. We listened to music.\n",
        "\n",
        "44. Where was she at 7 o’clock last night?\n",
        "\n",
        "45. Amelia chose to stay with her father.\n",
        "\n",
        "46. Mary forgot to turn off the light.\n",
        "\n",
        "47. I cancelled my meeting for tomorrow.\n",
        "\n",
        "48. I went to school yesterday.\n",
        "\n",
        "49. We played basketball last Sunday.\n",
        "\n",
        "50. We saw the Eiffel Tower.\n",
        "\n",
        "I didn't eat.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for sentence in test_past_tense.replace('\\n','').split('.')[1:-1]:\n",
        "    if len(sentence) < 3:\n",
        "        continue\n",
        "    if determine_tense_input(sentence)['present'] == 1:\n",
        "        pass\n",
        "        #print(sentence, determine_tense_input(sentence),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}