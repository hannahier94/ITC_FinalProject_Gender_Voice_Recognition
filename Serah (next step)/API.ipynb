{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans in c:\\users\\juvin\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from googletrans) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (2019.11.28)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.1.0)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.3.2)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (2020.6.16)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (2.8)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'utf8' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.24.1-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'utf8' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'utf8' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\juvin\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\juvin\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (0.14.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (4.4.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (0.48.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (0.22.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from librosa) (1.18.1)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (45.2.0.post20200210)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.14.0)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.14.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (20.1)\n",
      "Requirement already satisfied: requests in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.22.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from packaging->pooch>=1.0->librosa) (2.4.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\juvin\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'utf8' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !pip install googletrans\n",
    "# !pip install pydub\n",
    "# !pip3 install SpeechRecognition\n",
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\ilan avraham\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\ilan avraham\\anaconda3\\lib\\site-packages (from flask) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\ilan avraham\\anaconda3\\lib\\site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\ilan avraham\\anaconda3\\lib\\site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\ilan avraham\\anaconda3\\lib\\site-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ilan avraham\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Develop an api\"\"\"\n",
    "\n",
    "import librosa\n",
    "import spacy\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import warnings\n",
    "import en_core_web_sm\n",
    "from spacy.util import load_model\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, send_from_directory\n",
    "import numpy as np\n",
    "import json\n",
    "from googletrans import Translator\n",
    "from werkzeug.wrappers import Request, Response\n",
    "from werkzeug.utils import secure_filename\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "present_tenses = ['VBP', 'VBZ','VBG']\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def extract_spectrum(file_name, file_length=5, bin_factor=4, **kwargs):\n",
    "    \"\"\"\n",
    "    file_length is the target time length of the file in seconds\n",
    "    bin_factor is the amount by which we enlarge the time bins from 512 samples:\n",
    "    Extract mel spectrogram from audio file `file_name`\n",
    "    \"\"\"\n",
    "\n",
    "    X, sample_rate = librosa.core.load(file_name)\n",
    "    file_name = file_name.split('/')[-1]\n",
    "    target_name = file_name[:-4]\n",
    "    target_length = int(file_length * sample_rate)\n",
    "    target = np.zeros(target_length)\n",
    "    if X.shape[0] >= target_length:\n",
    "        target = X[:target_length]\n",
    "    else:\n",
    "        target[:X.shape[0]] = X\n",
    "    X = target\n",
    "    mel = librosa.feature.melspectrogram(X, sr=sample_rate, hop_length=512 * bin_factor).T\n",
    "    print(file_name, ' loaded with shape ', mel.shape)\n",
    "    return mel\n",
    "\n",
    "\n",
    "def open_model(filename=\"best_model_final.h5\"):\n",
    "    \"\"\" Given filename, returns the model\n",
    "    param filename: filepath for model\n",
    "    return : pretrained model \"\"\"\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        model = load_model(filename)\n",
    "    return model\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\" Given X, returns a prediction\n",
    "    param X: the feature values to consider\n",
    "    returns pred_pickle: the prediction \"\"\"\n",
    "\n",
    "    X = extract_spectrum(X).reshape(-1,54,128,1)\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        pred = model.predict(X)\n",
    "        if pred[0][0] <= 0.5:\n",
    "            return 'female'\n",
    "        else:\n",
    "            return 'male'\n",
    "\n",
    "def get_large_audio_transcription(X):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(X)\n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk\n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text\n",
    "\n",
    "\n",
    "\n",
    "def determine_chunks(pronouns, vals, text,present_tenses = present_tenses):\n",
    "    nlp = spacy.load('en')\n",
    "\n",
    "    present_tenses = ['VBP', 'VBZ','VBG']\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    iterations = len(pronouns)\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        start = vals[i]\n",
    "        stop = None\n",
    "\n",
    "        if i != (iterations - 1):\n",
    "            stop = vals[i+1]\n",
    "\n",
    "        if pronouns[i] != 'I':\n",
    "            chunks.append((str(text[start:stop]),0))\n",
    "            continue\n",
    "\n",
    "\n",
    "        present_verbs_change = [word for word in text[start:stop]\n",
    "                                if word.tag_ in\n",
    "                                present_tenses]\n",
    "\n",
    "        if len(present_verbs_change) == 0:\n",
    "            chunks.append((str(text[start:stop]),0))\n",
    "            continue\n",
    "\n",
    "        chunks.append((str(text[start:stop]),1))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def determine_tense_input(sentence, present_tenses = present_tenses):\n",
    "\n",
    "    \"\"\" Seperates words into chunks based on subjects of the sentence\n",
    "    and sends them to the determine_chunks function to determine\n",
    "    if that chunk requires further manipulation or not\n",
    "    param ....\n",
    "    .....\n",
    "    ....\n",
    "    returns: list of tuples (portion, int) where 1 means the chunk\n",
    "    requires further manipulation and 0 means it can be left as is \"\"\"\n",
    "\n",
    "    text = nlp(sentence)\n",
    "\n",
    "    present = len([word for word in text\n",
    "                    if word.tag_ in present_tenses])\n",
    "\n",
    "    if present == 0 :\n",
    "        return [(sentence,0)]\n",
    "\n",
    "    sub_toks = list(sorted([ (i, tok) for i, tok\n",
    "                            in enumerate(text)\n",
    "                            if tok.dep_ == \"nsubj\" ]))\n",
    "\n",
    "\n",
    "    vals = [x[0] for x in sub_toks]\n",
    "    pronouns = [str(x[1]) for x in sub_toks]\n",
    "\n",
    "    if 'I' not in pronouns:\n",
    "        return [(sentence,0)]\n",
    "\n",
    "    return determine_chunks(pronouns, vals, text)\n",
    "\n",
    "def get_translation(output, gender):\n",
    "    heb_I =  'אני'\n",
    "    heb_she = 'היא'\n",
    "    heb_he = 'הוא'\n",
    "    ind = []\n",
    "    translate = ''\n",
    "    lenght = 0\n",
    "    translator = Translator()\n",
    "    replacer = 'I'\n",
    "\n",
    "\n",
    "    for sentence, val in output:\n",
    "        res = translator.translate(sentence, dest='he').text\n",
    "        res_list = re.findall(r\"[\\w]+|['.,!?;]\", res)\n",
    "        if val>0:\n",
    "            if gender == 'female':\n",
    "                replacer = 'she'\n",
    "                heb_replacer = heb_she\n",
    "            elif gender == 'male':\n",
    "                replacer = 'he'\n",
    "                heb_replacer = heb_he\n",
    "            index = [i for i,x in enumerate(res_list) if x==heb_I][0]\n",
    "            ind.append(index+lenght)\n",
    "        lenght += len(res_list)\n",
    "        sentence_list = re.findall(r\"[\\w]+|['.,!?;]\", sentence)\n",
    "        sentence = ' '.join([replacer if word == 'I' else word for word in sentence_list])\n",
    "        translate += \" \" + sentence\n",
    "    gender_res = translator.translate(translate, dest='he').text\n",
    "    gender_res_list = re.findall(r\"[\\w]+|['.,!?;]\", gender_res)\n",
    "    for i in ind:\n",
    "        if gender_res_list[i] == heb_replacer:\n",
    "            gender_res_list[i] = heb_I\n",
    "        elif gender_res_list[i-1] ==  heb_replacer:\n",
    "            gender_res_list[i-1] = heb_I\n",
    "        elif gender_res_list[i+1] ==  heb_replacer:\n",
    "            gender_res_list[i+1] = heb_I\n",
    "\n",
    "    return ' '.join(gender_res_list)\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.secret_key = 'some secret'\n",
    "\n",
    "'''limiting the receiving file to 2 MB maximum'''\n",
    "app.config['MAX_CONTENT_LENGTH'] = 2 * 1024 * 1024\n",
    "\n",
    "UPLOAD_FOLDER = '~/Desktop/ITC_Final_Project/ITC_FinalProject_Gender_Voice_Recognition/yuval/uploads'\n",
    "'''configuring uploading folder'''\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "'''setting accepted files to the server'''\n",
    "ALLOWED_EXTENSIONS = {'wav', 'mp3'}\n",
    "\n",
    "os.chdir('C:/Users/Juvin/Desktop/ITC_Final_Project/ITC_FinalProject_Gender_Voice_Recognition/Serah (next step)')\n",
    "model = open_model()\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/uploads/<filename>')\n",
    "def uploaded_file(filename):\n",
    "    return send_from_directory(app.config['UPLOAD_FOLDER'],\n",
    "                               filename)\n",
    "\n",
    "@app.route(\"/prediction\", methods = ['POST'])\n",
    "def prediction():\n",
    "    if request.method == 'POST':\n",
    "        \n",
    "        # check if the post request has the file part\n",
    "        if 'file' not in request.files:\n",
    "            print('no!')\n",
    "            flash('No file part')\n",
    "            return redirect(request.url)\n",
    "        \n",
    "        file = request.files['file']\n",
    "        # if user does not select file, browser also\n",
    "        # submit an empty part without filename\n",
    "        if file.filename == '':\n",
    "            print('yes!')\n",
    "            flash('No selected file')\n",
    "            return redirect(request.url)\n",
    "        \n",
    "        if file and allowed_file(file.filename):\n",
    "            print('awesome!')   \n",
    "            filename = secure_filename(file.filename)\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "#             return redirect(url_for('uploaded_file',\n",
    "#                                     filename=filename))\n",
    "        '''predict gender'''\n",
    "        pred = predict(filename)\n",
    "        '''speech to text'''\n",
    "        chunks = get_large_audio_transcription(filename)\n",
    "        split_sentence = determine_tense_input(chunks)\n",
    "        '''modify translation as necessary'''\n",
    "        output = get_translation(split_sentence, pred)\n",
    "        '''prep a json to delivery'''\n",
    "        json = {'pred':pred, 'output':output}\n",
    "    \n",
    "        return json\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [25/Sep/2020 18:12:10] \"\u001b[32mPOST /prediction HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Sep/2020 18:12:11] \"\u001b[31m\u001b[1mGET /prediction HTTP/1.1\u001b[0m\" 405 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
